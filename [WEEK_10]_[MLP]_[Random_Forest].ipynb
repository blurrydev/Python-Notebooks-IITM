{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[WEEK 10] [MLP] [Random Forest].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMx+IZ2aYbX1D8xjV2iytgy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blurrydev/Python-Notebooks-IITM/blob/main/%5BWEEK_10%5D_%5BMLP%5D_%5BRandom_Forest%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this colab, we will implement multiclass MNIST digit recogntion clasifier with decision trees and ensemble techniques."
      ],
      "metadata": {
        "id": "tZgtbKpn2gvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing basic libraries**"
      ],
      "metadata": {
        "id": "_ecu8DuE2z8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-q6MrO50mYi"
      },
      "outputs": [],
      "source": [
        "# plotting utility\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# dataset loading through mnist\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# training three classifiers: decision tree, bagging and random forest\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# model selection utilities for training and test split & cross validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# use Shuffle-split cross validation for this excercise\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "# make use of confusion matrix and classification report to evaluate\n",
        "# performance on this set\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# the model is defined through pipeline utility\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading MNIST dataset"
      ],
      "metadata": {
        "id": "Y54X2OQ_4t13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by loading the MNIST dataset with `load_data` function in `mnist` class.\n",
        "\n",
        "We obtain:\n",
        "- Training feature matrix and labels\n",
        "- Test feature matrix and labels"
      ],
      "metadata": {
        "id": "gWC-Vl4e40XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "YZueSpIm6i0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you know there are 60000 examples in the training set.\n",
        "\n",
        "Each example is a grey scale image of 28*28. There are 10 different labels - one for each digit - 0 to 9"
      ],
      "metadata": {
        "id": "GL27wBqQ6s-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training data', X_train.shape)\n",
        "print('Shape of training labels', y_train.shape)\n",
        "print('Shape of test data', X_test.shape)\n",
        "print('Shape of test labels', y_test.shape)"
      ],
      "metadata": {
        "id": "xJ2Pclp06-tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before using dataset for training and evaluation, we need to flatten it into"
      ],
      "metadata": {
        "id": "QFad2jFW3l1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EsLnOHF43h9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}